%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% document class
\documentclass[a4paper,11pt,oneside]{book}

%% packages
\input{settings/packages}

%% page settings
\input{settings/page}

%% own commands
%\newcommand{\tbi}[1]{\textbf{\textit{#1}}}
\input{settings/macros}
\newcommand{\imp}[1]{\underline{\textit{#1}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	%\pagestyle{empty}
	%\title{Basic elements for writing a book/thesis using \LaTeX}
	%\autr{Mauricio Lobos}
	%\date{}
	%\maketitle
	\input{content/title_page_1} % downloaded template
	
	%\pagestyle{plain}
	%\listoftodos
	\tableofcontents
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Motivation}

Basel I (Basel Accord) is the agreement reached
in 1988 in Basel (Switzerland) by the Basel Committee on Bank
Supervision (BCBS), involving the chairmen of the central banks
of some European countries and
the United States of America. This accord provides recommendations
on banking regulations with regard to credit, market and
operational risks. It aims to ensure that financial institutions
hold enough capital on account to meet obligations and absorb
unexpected losses. \newline\newline
For a financial institution measuring the risk it faces is an essential
task. In the specific case of market risk, a possible method of
measurement is the evaluation of losses likely to be incurred when
the price of the portfolio assets falls. This is what Value at Risk
(VaR) does.\newline\newline
Value at Risk(VaR) is the most common way of measuring market risk. It determines the greatest possible loss, assuming an $\alpha$ significance level under a normal market condition at a set time period.\newline\newline
Many VaR estimation methods have been developed in order to reduced uncertainty. It is however of interest to compare these method and determine the prevalence of one VaR estimation approach over others.






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\section{Literature review}

The first papers involving the comparison of VaR methodologies, such as those by Beder (1995, 1996), Hendricks (1996), and
Pritsker (1997), reported that the Historical Simulation performed at least as well as the methodologies developed in the early years, the Parametric approach and the Monte Carlo simulation. These papers conclude that among earlier methods, no approach appeared to perform better than the
others. The evaluation and categorization of models carried out in the work by McAleer, Jimenez-Martin and Perez-Amaral(2009) and Shams and Sina (2014), among others, try to determine the conditions under which certain models predict the best. Researchers compared models in periods of varying volatility-before the crisis and after the crisis (When there was no high volatility and when volatility was high, respectively). However, this confirms that some models have good predictions before the start of the crisis, but their quality reduces with increased volatility. Others are more conservative during periods of low volatility, but in the time of the crisis the number of errors made by these models is relatively low.
\newline\newline
Bao et al.(2006), Consigli(2002) and Danielson(2002), among
others, show that "in stable periods, parametric models provide satisfactory results
that become less satisfactory during high volatility periods".  Additional studies that find
evidence in favour of parametric methods are Sarma et al.(2003), who compare
Historical simulation and Parametric methods, and Danielson and Vries(2000) in a
similar comparison that also includes Extreme value theory methods. Chong(2004),
who uses parametric methods to estimate VaR under a Normal distribution and under a
Student’s t-distribution, finds a better performance under Normality. McAleer et al.(2009) showed that RiskMetrics\textsuperscript{TM} was
the best fitted model during a crisis, while Shams and Sina(2014) recognized GARCH(1,1) and GJR-GARCH as well
forecasting models. In contrast to the results obtained
by McAleer et al.(2009), the level of quality of forecasts
generated by the RiskMetrics\textsuperscript{TM} model was considered
unsatisfactory by them. However, attention needs to be
drawn to one difference in the samples, on which the
study was conducted, i.e. the first one comes from a
developed country (USA, S\&P500), and the second one
from a developing country (Iran, TSEM). Taylor(2020) evaluate Value at Risk using quantile skill score and the conditional autoregressive model outperformed others.
\newline\newline

Attempts have been made to predicts VaR with ANN. VaR estimation on the exchange rate market in the context of ANNs is dealt with in
Locarek-Junge and Prinzler (1999), who illustrate how VaR estimates can be obtained
by using a USD-portfolio. The empirical outcomes demonstrate an evident superiority
of the neural network to other VaR models. Hamid and Iqbal(2004) compared volatility forecasts from neural networks with forecasts of implied volatility from S\&P500 index futures options, using the Barone-Adesi and Whaley (BAW) American futures options pricing model. Forecasts from NN outperformed implied volatility forecasts. Similar results are put forth by He et al.
(2018), who propose an innovative EMD-DBN type of ANN to estimate VaR on the
USD against the AUD, CAD, CHF and the EUR. The authors find positive
performance improvement in the risk estimates, and argue that the utilization of an
EMD-DBN network can identify more optimal ensemble weights and is less sensitive
to noise disruption compared to a FNN. Nevertheless, it is worthwhile to mention that although
foreign exchange volatility forecasting through ANNs have gained some attention in
the academic field, it still remains a fairly undeveloped area.
\newline\newline
All in all, there is no full approval in the evaluation of which models should be used during
periods of calm (low volatility), and which ones during crisis (High volatility).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Thesis Structure}
The next chapter of discusses the properties and basic methods to estimate VaR. Subsequent chapters discuss use of Neural Network in Estimating Value at Risk and numerical comparison of the methods with examples. Findings are summarized in the last chapter.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Value-at-Risk: Concept,  properties and methods}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Concept}
Higher volatility in exchange markets, credit defaults, even endangering countries, and the call for more regulation drastically changed the circumstances in which banks operate. These situations of uncertainty are called risks and managing them is of great importance to financial institutions (e.g Banks) in order to keep them afloat. A possible method of measurement is the evaluation of losses likely to be incurred when the price of the portfolio falls. Value at Risk (VaR) does this.
\newline\newline
According to Jorion (2001), “VaR measure is defined as the worst
expected loss over a given horizon under normal market conditions
at a given level of confidence. For instance, a bank might say that
the daily VaR of its trading portfolio is \$2 million at the 99\%
confidence level. In other words, under normal market conditions,
only 1\% of the time, the daily loss will exceed \$2 million (99\% of the time, their loss will not be more than \$2 million)”. As represented in the mathematical representation below, it can also be stated as the least expected return of a portfolio at time $t$ and at a certain level of significance, $\alpha$.
\newline\newline
Mathematically,\newline\newline
Let $r_1, r_2, ..., r_n$ be independently and identically distributed(iid) random variables representing financial log returns. Use $F(r)$ to denote the cumulative distribution function,
$F(r) = Pr(r_{t} < r|\Omega_{t-1})$ conditional on the information set $\Omega_{t-1}$ available at time $t$-1. Assume that \{$r_t$\} follows the stochastic process; \newline

\begin{equation}
\begin{aligned}
r_t &= \mu_t + \varepsilon_t
\\
\varepsilon_t &= \sigma_t  z_t \qquad   z_t \sim iid(0,1)
\label{1}
\end{aligned}
\end{equation}

where $\sigma^2_t = E[z^2_t|\Omega_{t-1}]$ and $z_t$ has a conditional distribution function $G(z)$, $G(z) = Pr(z_t < z|\Omega_{t-1})$. The VaR with a given probability $\alpha$ $\epsilon(0,1)$, denoted by VaR($\alpha$), is defined as the $\alpha$ quantile of the probability distribution of financial returns:\newline
$F(\text{VaR}(\alpha))=Pr(r_t < \text{VaR}(\alpha))=\alpha$ or $\text{VaR}(\alpha)$ = inf$\{v|P(r_t \leq v)= \alpha\}$
\newline\newline
One can estimate this quantile in two different ways: (1) inverting the distribution function of financial returns, F(r), and (2)
inverting the distribution function of innovations, with regard to
$G(z)$ the latter, it is also necessary to estimate $\sigma^2_t$.

\begin{equation}
\text{VaR} (\alpha) = F^{-1}(\alpha) = \mu + \sigma_tG^{-1}(\alpha)
\label{2}
\end{equation}

Hence, a VaR model involves the specification of $F(r)$ or $G(r)$. There are several method for these estimations. Having explained the concept of Value at Risk, it is however necessary to state some of its properties or attributes.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Properties}

%Fix $\alpha$ $\epsilon$(0,1), then the Value at Risk of a portfolio %where the net payoff is modelled by X at a level $\alpha$ is given %as:\newline
%$\text{VaR}_{\alpha}(X)$ = inf $\{x \epsilon \mathbb{R}| P(X \leq %x)=\alpha\}$. Value at risk as a risk measure satisfies the following %properties
A functional $\tau: X,Y \rightarrow \mathbb{R} \cup \{+\infty\}$ is said to be coherent risk measure for portfolios $X$ and $Y$ if it satisfies the following properties:
\newline

\begin{description}
	\item[$\bullet$] Normalization \newline $\tau[0] = 0$ \newline The risk when holding no assets is zero.
	\item[$\bullet$] Monotonicity \newline if $X \leq Y$ then $\tau(X) \geq \tau(Y)$ \newline For financial applications, this implies that a
	security that always has higher return in all future states has less risk of loss.
	
	\item[$\bullet$] Translation invariance
	\newline  $\tau(X+c) = \tau(X)-c$ \newline In effect, if an amount of cash κ (or risk free asset)
	is added to a portfolio, then the risk is reduced by that amount.
	\item[$\bullet$] Positive Homogeneity
	\newline $\tau(cX) = c\tau(X)$ if $c>0$. \newline In effect, if a portfolio or capital asset is, say,
	doubled, then the risk will also be doubled.
	
		\item[$\bullet$] subadditivity: 
	\newline $\tau(X+Y)\leq \tau(x)+\tau(Y)$. 
	Indeed, the risk of two portfolios together cannot get any worse than adding the two risks separately: this is the diversification principle.
	
\end{description}
Out of the above properties, all but subaddivitivity is not always satisfied by VaR. This is however a disadvantage of value at risk as a risk measure because it might discourage diversification.

\section{Popular methods for estimating VaR}
The estimation of these functions ($F(r)$ or $G(r)$) can be carried out using the
following methods:

\subsection{Historical simulation}

The historical simulation involves using past data to predict future. First of all, we
have to identify the market variables that will affect the portfolio. Then, the data
will be collected on the movements in these market variables over a certain time
period. This provides us the alternative scenarios for what can happen between
today and tomorrow. For each scenario, we calculate the changes in the dollar
value of portfolio between today and tomorrow. This defines a probability
distribution for changes in the value of portfolio. For instance, VaR for a portfolio
using 1-day time horizon with 99\% confidence level for 500 days data is nothing
but an estimation of the loss when we are at the fifth-worst daily change.
\newline\newline Basically, historical simulation is extremely different from other type of
simulation in that estimation of a covariance matrix is avoided. Therefore, this approach has simplified the computations especially for the cases of complicated
portfolio.\newline\newline
The core of this approach is the time series of the aggregate portfolio return. More
importantly, this approach can account for fat tails and is not prone to the
accuracy of the model due to being independent of model risk. As this method is
very powerful and intuitive, it is then become the most widely used methods to
compute VaR. However, Historical simulation requires data on all risk factors to be available over a reasonably long historical period in order to give a good
representation of what might happen in the future. As it depends on history, if we run a Historical Simulations VaR in a bull market, VaR may be underestimated. Similarly, if we run a Historical Simulations VaR just after a crash, the falling returns which the portfolio has experienced recently may distort VaR.
\subsection{GARCH Model}
The Generalized Autoregressive Conditional Heteroskedasticity(GARCH) model, proposed by Bollerslev
(1986) is a generalization of the ARCH process created by
Engle (1982), in which the conditional variance is not only
the function of lagged random errors, but also of lagged
conditional variances. The standard GARCH model ($p,q$)
can be written as:
\begin{equation}
\begin{aligned}
r_t &= \mu_t + \varepsilon_t
\\
\varepsilon_t &= \sigma_t \xi_t 
\label{6}
\end{aligned}
\end{equation}
where $r_t$ = rate of return of the asset in the period $t$,\newline
$\mu_t$ =conditional mean \newline

$\varepsilon_t$ = random error in the period $t$, which equals to the
product of conditional standard deviation $\sigma_t$ and  the
standardized random error $\xi_t$ in the period $t$ ($\xi_t$ $\sim$ iid(0,1))
\newline\newline
In turn, the equation of conditional variance, in the GARCH($p$,$q$) model can be written as:


\begin{equation}
\begin{aligned}
\sigma^2_t = \omega + \sum_{i=1}^{q}\alpha_{i}\varepsilon^{2}_{t-i} + \sum_{i=1}^{p}\beta_{i} \sigma^2_{t-i}
\label{7}
\end{aligned}
\end{equation}
where $\sigma^2$ =conditional variance in the period $t$,\newline
$\omega$ = constant ($\omega>0$)\newline
$\alpha_{i}$ = weight of the random squared error in the period $t-1$,\newline
$\beta_{i}$ = weight of the conditional variance in the period $t-1$,\newline
$\varepsilon^{2}_{t-i}$= squared random error in the period $t-1$,\newline
$\sigma^2_{t-i}$ =variance in the period $t-1$,\newline
$q$ = number of random error squares periods used in the functional form of conditional variance,\newline
$p$ = number of lagged conditional variances used in the
functional form of conditional variance (see Buczyński \& Chlebus (2018)).\newline\newline Ruilova \& Morettin (2020) "When we use high frequency data in conjunction with GARCH models, these need to be modified
to incorporate the financial market micro structure. For example, we need to incorporate heterogeneous
characteristics that appear when there are many traders working in a financial market trading with
different time horizons. The HARCH(n) model was introduced by Müller et al. (1997) to try to solve this problem".

\subsection{HAR Method}

High frequency data are those measured in small time intervals. This kind of data is important
to study the micro structure of financial markets and also because their use is becoming feasible
due to the increase of computational power and data storage. The HARCH(n) model was
introduced by Müller et al. (1997) to estimate the VaR for this kind of data. In fact, this model incorporates
heterogeneous characteristics of high frequency financial time series and it is given by 
\begin{equation}
\begin{aligned}
r_t &= \sigma_t\varepsilon_t
\\
\\
\sigma^2 &= c_0 + \sum_{j=1}^{n}c_j\left(\sum_{i=1}^{j}r_{t-i}\right)^2
\label{3}
\end{aligned}
\end{equation}
where $c_0>0, c_n > 0, c_j \ge 0$ $\forall j = 1,...,n-1$ and $\varepsilon_t$ are identically and independent distributed (i.i.d.) random variables with zero expectation and unit variance and the $c_j$ are parameters estimated using least squares.
\newline
\newline
Intraday data have been found to be useful in estimating features of the distribution of daily returns. For
example, the realized volatility has been used widely
as a basis for forecasting the daily volatility. The heterogeneous autoregressive (HAR) model of the realized
volatility is a simple and pragmatic approach, where a
volatility forecast is constructed from the realized volatility over different time horizons (Corsi, 2009). However,
intraday data can be expensive, and resources are required for pre-processing. Given the ready availability
of the daily high and low prices, an alternative way of
capturing the intraday volatility is to use the intraday range. Where $\text{Range}_{t}$
is the difference between the highest and
lowest log prices on day $t$, to predict tomorrow's range from past daily, weekly, monthly averages of $\text{Range}_{t}$, we set up the linear regression model;

\begin{equation}
\begin{aligned}
\text{Range}_{t}&=\beta_1+\beta_{2}\text{Range}_{t-1} + \beta_{3}\text{Range}^{w}_{t-1} + \beta_{4}\text{Range}^{m}_{t-1} + \varepsilon_t
\\
\\
\text{Range}^{w}_{t-1}&=\frac{1}{5}\sum_{i=1}^{5}\text{Range}_{t-i}
\\
\\
\text{Range}^{m}_{t-1}&=\frac{1}{22}\sum_{i=1}^{22}\text{Range}_{t-i}
\label{4}
\end{aligned}
\end{equation}

where $\text{Range}_{t}$
is the difference between the highest and
lowest log prices on day $t$; $\text{Range}^{w}_{t-1}$
and $\text{Range}^{m}_{t-1}$ are
averages of $\text{Range}_{t}$ over a week and month, respectively;
$\varepsilon_t$
is an i.i.d. error term with zero mean; and the $\beta_{i}$
are parameters that are estimated using least squares.
The conditional variance is then expressed as a linear
function of the square of $\text{Range}_{t}$
, where the intercept and
the coefficient are estimated using maximum likelihoods
based on a Student t distribution.


\subsection{CaViaR Method}
Engle and Manganelli (2004) propose a conditional autoregressive quantile specification (CAViaR) quantile estimation. Instead of modeling the whole distribution, the quantile is modelled directly. The empirical fact that volatilities of stock market returns cluster over time may be translated in statistical words by saying that their distribution is autocorrelated. Consequently, the VaR, which is a quantile, must behave in similar way. A natural way to formalize this characteristic is to use some type of autoregressive specification
\newline\newline
let $\{y_t\}^T_{t=1}$ and $\theta$ be a vector of portfolio returns and the probability associated with VaR respectively. Let $x_t$ be a vector of time t observable variables(return or any other observable variables), and ${\beta}_\theta$ be a $p$-vector of unknown parameters. Finally, let $f_t(\beta) $ $\equiv$ $ f_t(x_{t-1},{\beta}_\theta)$ denote the time $t$ $\theta$-quantile of the distribution of the portfolio returns formed at $t-1$, The $\theta$ subscript is however suppressed from $\beta_\theta$ for convenience in notation: The general specification of CaViar would be:
\begin{equation}
\begin{aligned}
f_t(\beta)=\beta_0 + \sum_{i=1}^{q} \beta_{i}f _{t-i}(\beta) +\sum_{j=1}^{r}\beta_{j}l(x_{t-j})
\label{5}
\end{aligned}
\end{equation}
where $p=q+r+1$ is the dimension of $\beta$ and $l$ is a function of a finite number of lagged values of observables. The autoregressive terms $\beta_{i}f_{t-i}(\beta)$, $i = 1,...,q$, ensure that the quantile changes smoothly over time. The parameters of CaViaR are estimated by quantile regression. The role of $l(x_{t-j})$ is to connect $f_{t}(\beta)$ to observable variables that belong to the information set.
\newline\newline
The asymmetric slope is a variant of CaViar model, which allows the response to positive and negative returns to be different. It is modelled as:\newline\newline
$f_{t}(\beta)= \beta_{1} +\beta_{2}f_{t-1}(\beta)+\beta_{3}(y_{t-1})^{+} + \beta_{4}(y_{t-1})^{-}$. where, $(y_{t-1})^{+}$= max($y_{t-1}$, 0) and $(y_{t-1})^{-}$ = -min($y_{t-1}$, 0)
\newline\newline
\textbf{Note:} In this work, value at risk will be estimated based on financial log-returns. Historical simulation, Garch models, and long short term memory neural network will be used for our VAR estimation. The latter will be discussed in the next chapter.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Estimating VaR using Neural Networks
}
Neural networks, also known as artificial neural networks (ANNs) are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Their name and structure are inspired by the human brain, mimicking the way that biological neurons signal to one another.\newline\newline

Neural networks are made of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node (or artificial neuron), connects to another and has an assigned weight and threshold. If the output of any individual node exceeds the specified threshold value, that node is activated, transferring data to the next layer of the network. Else, no data is passed along to the next layer of the network.
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.7\textwidth]{figures/NN}
	\caption{A figure showing the layers of a Neural Network (see IBM, 2020)}
	\label{firstfig}
\end{figure}\newline
Neural networks rely on training data to learn and improve their accuracy over time. However, once these learning algorithms are polished for accuracy, they become powerful tools in computer science and artificial intelligence, allowing us to classify and cluster data at a high speed. Tasks in speech recognition or image recognition can take minutes versus hours when compared to the manual identification by human experts.
\newline\newline
Neural network is good for returns prediction as it can accommodate nonlinear interactions, and no distribution is assumed. However, just like historical simulation they require large data set (which is not always available) for training to perform excellently well.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Mathematics of Neural Network}
The main idea of this section is gotten from the work of Chaoyi Lou, titled Artificial Neural Networks:
their Training Process and Applications.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{A single Neuron}
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.7\textwidth]{figures/neuron}
	\caption{A single neuron of neural networks}
	\label{secondfig}
\end{figure}

\autoref{secondfig} shows a network with one layer containing a single neuron. This neuron receives input from the prior input layer, performs computations, and gives output. $x_1$ and $x_2$ are inputs with weights $w_1$ and $w_2$ respectively. The neuron applies a function $f$ to the dot-product of these inputs, which is $w_{1}x{1}+w_{2}x_{2}+b$.  Besides the two numerical input values, there is one input value 1 with weight $b$, called the Bias. The main function of bias is to stand for unknown parameters or unforeseen factors. The output $Y$ is computed by taking the dot-product of all input
values and their associated weights and putting it into the function $f$. This function is called the Activation Function.\newline\newline
Activation functions are needed because many problems take multiple influencing factors into account and yield classifications. For example, if one encounters a binary classification problem, the results would
be either yes or no, activation functions are needed to map the results
inside this range. If one encounters a problem involving probability, then
one would wish to see the predictions from the neural network being in
the range of [0, 1]. This is what activation functions can do.\newline\newline
There are two types of activation functions: linear activation
functions and non-linear ones. The biggest limitation of linear ones is
that they cannot learn complex function mappings because they are
just polynomials of one degree. Therefore, we always need non-linear
activation functions to produce results in desired ranges and to send
them as inputs to the next layer. The following subsection will introduce
few generally used non-linear activation functions.
\subsection{Activation Functions}
An activation function takes the dot-product mentioned before as a input and performs a certain computation on it. We put a certain activation function inside of neurons of hidden layers based on the range of
the result we expect to see. A notable property of activation functions is that they should
be differentiable, because later we need this property to train the neural network using backpropagation optimization.
\newline\newline
Here are few commonly used activation functions:\newline\newline
\textbf{Sigmoid}: This takes a real-valued input and returns a output in the range [0,1]:\newline\newline
$\delta = \frac{1}{1+e^{-x}}$
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.4\textwidth]{figures/neuro}
	\caption{Sigmoid() Activation Function}
	\label{thirdfig}
\end{figure}

\autoref{thirdfig} shows an S-shaped curve and the values going
through the Sigmoid function will be squeezed in the range of [0, 1].
Since the probability of anything exists only between the range of 0 and
1, Sigmoid is a compatible transfer function for probability.
Although the Sigmoid function is easy to understand and ready
to use, it is not frequently used because it has vanishing gradient
problem. This problem is that, in some cases, the gradient gets so close to zero that it does not effectively apply change to the weight. In the
worst case, this may completely stop the neural network from further
training. Second, the output of this function is not zero-centered, which
makes the gradient updates go far in different directions. Besides, the
fact that output is in the narrow range [0, 1] makes optimization harder.
In order to compensate the shortcomings, tanh() is an alternative option
because it is a stretched version of the Sigmoid function, in which its
output is zero-centered. \newline\newline
\textbf{tanh}: This takes real-valued input and produces the results in the range [-1, 1]:\newline\newline
$\text{tanh(x)}=\frac{sinh(x)}{cosh(x)}=\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}$

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.4\textwidth]{figures/tanh}
	\caption{tanh() Activation Function}
	\label{fourthfig}
\end{figure}

The advantage is that the negative input values will be mapped
strongly negative and very small values close to zero will be mapped to values close to zero through this
function. Therefore, this function is useful in the performance of a classification between two distinct classes.
Though, this function is preferred over the Sigmoid function in practice (output in wider range), but the gradient vanishing
problem still exists. The following ReLU function rectifies this problem
using a relatively simple formula.\newline\newline

\textbf{ReLU} (Rectified Linear Unit): It takes a real-valued input and replaces the negative values with zero:
\newline\newline
$R(x)= \text{max}(0,x)$
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.4\textwidth]{figures/Relu}
	\caption{ReLU() Activation Function}
	\label{fifthfig}
\end{figure}
\newline\newline It is used in almost all the convolutional neural networks or deep learning because it is a relatively simple and efficient
function which avoids and rectifies the gradient vanishing problem.
The problem of this activation function is that all the negative
values become zeros after this activation, which in turns affects the
results by not taking negative values into account.
\newline\newline We use different activation functions when we know what characteristics of results we expect to see.
 \section{General Model Building}
 Having discussed the mathematics behind neural network, it is however in important to talk about the neural network architectures and other components
 \subsection{Neural network Architures}
 Neural Networks are complex structures made of artificial neurons that can take in several inputs to produce a single(or more) output(s). Normally, a Neural Network consists of an input and output layer with one or multiple hidden layers within. In a Neural Network, all the neurons(contained in each layers) influence each other, and hence, they are all connected. The manner in which the input neurons produce a certain output is intimately linked
 to the structure of the neural network. The two main classes of network architectures are discussed below
 \subsubsection{Feed-forward Neural Network} (see Bijelic \& Ouijjane, 2019)
 In feed-forward neural network(FFN), each neuron in a
 particular layer is connected with all neurons in a subsequent layer. The information
 flow in the network is of feedforward type (i.e the connections
 can never skip a layer, or form any loops backwards).\newline
 \begin{figure}
 	\centering
 	\includegraphics[width=0.4\textwidth]{figures/FFN}
 	\caption{A fully connected FFN with a single hidden layer (see Bijelic \& Ouijjane, 2019)}
 	
 	\label{sixthfig}
 \end{figure}
\newline
 As shown in the above figure, the values of the input are transported to the hidden layer through connections, each being characterised by certain weight coefficient, $W_{i,k}$. The degree of connection between the input node and a hidden node is reflected by these weight coefficients. Defining [$x_{1,t};x_{2,t};...;x_{n,t}$] as the vector of the input signals and [$h_{1,t};h_{2,t};...;h_{m,t}$], the propagation of the input nodes to one hidden node can
 mathematically be described by: \newline
 \begin{center}


 $h_{k,t} =\sum_{i=1}^{n} W_{i,k} \cdot x_{i,t}$ for $k = 1,2,...,m$
  \end{center}
An undesirable property of the formula is its linear representation,
which, if applied, would suggest that the output prediction would be a linear function, which is not always the case. In order to deal with this, a non-linear activation function, $\Phi(\cdot)$ is applied to the weighted sum of
inputs into a hidden node. This activation function, which in the majority of
applications takes the form of a sigmoid function or a ReLu function, makes the neural network capable of approximating virtually any function. However, before applying
the activation function, a bias vector [$b_{1};b_{2};...;b_{m}$] is added, which essentially
indicates whether a neuron tends to be active or inactive in the prediction process. The
propagation from the input layer to the hidden layer in a feed-forward neural
network can then be reformulated to:
 \begin{center}
	$h_{k,t} =\Phi(b_{k,0} +\sum_{i=1}^{n} W_{i,k} \cdot x_{i,t}$) for $k = 1,2,...,m$
\end{center}
Although the model-free assumption underlying the feedforward neural network
theoretically suggests that it should far better than the conventional GARCH(1,1) in
predicting volatility, the feedforward neural network is subject to a
major concern in that it precludes modelling time-dependencies in the data. This
deficiency of not being able to take correlations between inputs into account is
however resolved in the recurrent neural network, which is able to selectively pass
information across sequences of elements by creating cycles in the network.
\subsubsection{Recurrent Neural Network} (see Bijelic \& Ouijjane, 2019)
Recurrent Neural Networks
(RNN) can handle sequential data due to the capability of each neuron to
maintain information about previous inputs, contrary feedforward neural networks. This means that the prediction a recurrent
neural network node made at previous time step $t-1$ affects the prediction it will make one
moment later, at time step $t$. RNN nodes can be thought of as having memory as it takes inputs not only the current signal, but also
what has been perceived previously in time.\newline\newline
RNNs contain feedback loops from the so-called hidden states, and this allows preservation of information from one node to another while reading in inputs. This feedback loop
mechanism occurs at each time step in the data series, which results in each hidden
state containing traces not only of the previous hidden state, but also of all the
preceding ones, for as long as the memory of the network persists (Skymind, 2019).\newline

\begin{figure}
	\centering
	\includegraphics[width=0.4\textwidth]{figures/RNN}
	\caption{Representation of an unrolled plain vanilla recurrent neural network. (see Bijelic \& Ouijjane, 2019)}
	
	\label{seventhfig}
\end{figure}

The unrolled RNN illustrates how the network allows the hidden neurons to see their
own previous output, so that their subsequent behavior can be shaped by previous
responses (Tenti, 1996). Furthermore, by introducing time-lagged model components,
it becomes evident that the utilization of a RNN is particularly desired when there are
time dependencies in the data series at hand.
Using the previous notation and assuming that the hidden states are the ones looped
back, the output from a hidden node in the RNN model depends on the input values at
time $t$, but also on its own lagged values at order $p$ as shown below:

\begin{center}
	$h_{k,t} =\Phi(b_{k,0} + \sum_{i=1}^{n} W_{i,k} \cdot x_{i,t}) + \sum_{k=1}^{m} \gamma_{k} \cdot h_{k,t-p}$for $k = 1,2,...,m$
\end{center}

where $h_{k,t-p}$ represents the lagged hidden state values at order $p$, and $\gamma_{k}$ a coefficient. Another distinguishing characteristic of recurrent networks is that they share parameters across each layer of the network. While feedforward networks have different weights across each node, recurrent neural networks share the same weight parameter within each layer of the network. That said, these weights are still adjusted in the through the processes of backpropagation and gradient descent to facilitate reinforcement learning. Recurrent neural networks leverage backpropagation through time (BPTT) algorithm to determine the gradients, which is slightly different from traditional backpropagation as it is specific to sequence data. The principles of BPTT are the same as traditional backpropagation, where the model trains itself by calculating errors from its output layer to its input layer. These calculations allow us to adjust and fit the parameters of the model appropriately. BPTT differs from the traditional approach in that BPTT sums errors at each time step whereas feedforward networks do not need to sum errors as they do not share parameters across each layer.\newline\newline

Through this process, RNNs tend to run into two problems, known as exploding gradients and vanishing gradients. These issues are defined by the size of the gradient, which is the slope of the loss function along the error curve. When the gradient is too small, it continues to become smaller, updating the weight parameters until they become insignificant—i.e. 0. When that occurs, the algorithm is no longer learning. Exploding gradients occur when the gradient is too large, creating an unstable model. In this case, the model weights will grow too large, and they will eventually be represented as NaN. One solution to these issues is to reduce the number of hidden layers within the neural network, eliminating some of the complexity in the RNN model(see, IBM 2020).


\subsubsection{Long Short-Term Memory Recurrent Neural Network}
Originally introduced by Hochreiter and Schmidhuber (1997), a main characteristic of LSTMs – which are a sub class of recurrent neural networks - is its purpose-built memory cells, which allows it to capture long range dependencies in the data. From a model perspective, LSTMs differ from other neural network architectures in that they are applied recurrently.\newline\newline
The output from a previous sequence of the network function serves – in combination with the next sequence element - as input for the next application of the network function. In this sense, the LSTM can be interpreted as being similar to an HMM (Hidden Markov Model), in that there is a hidden state which conditions the output distribution. However, the LSTM hidden state not only depends on its previous states, but it also captures long term sequence dependencies through its recurrent nature. Maybe most notably, the receptive field size (i.e the size of the region in the input that produces the feature) of an LSTM is not bound architecture wise as in case of simple feed forward network and CNN. Instead, the LSTM’s receptive field depends solely on the LSTMs ability to memorize the past input (Arimond et al, 2020). \newline\newline Due to the attractiveness of the LSTM, it will be used in this work to forecast volatility of returns of stock markets. \newline\newline

\section{The LSTM Architecture}
Our LSTM has a single hidden layer,  with 'tanh' as the activation function. The following are the hyper parameter used in within the LSTM neural network:
\begin{itemize}

\item[$\bullet$]   
Optimizers are algorithms used to change the properties of the neural network such as weights and learning rate to minimize the losses. Adam is the chosen optimizer in our LSTM model. Some of its advantages are that the magnitudes of parameter updates are invariant to
rescaling of the gradient, its stepsizes are approximately bounded by the stepsize hyperparameter,
it does not require a stationary objective, it works with sparse gradients, and it naturally performs a
form of step size annealing (Kingma and Ba, 2015).
\item[$\bullet$] The batch size is the number of inputs that will be propagated in the
LSTM neural network during the training process. In our LSTM model 128 is the chosen batch size, and this means that the volatility inputs are
fed in the network in batches, each containing 128 inputs. After
the propagation of a batch, the network is trained before receiving another
batch of 128 inputs. This operation continues until all inputs are propagated.
\item[$\bullet$] The look ahead is the amount of time steps, i.e. the lagged
inputs the RNN should use to forecast the desired outputs. For all trials, the look back is set to 90 lagged inputs, which
corresponds to about 3-month period in the data sample.
\item[$\bullet$] The dropout function is a regularization method used to prevent overfitting by
allowing the LSTM neural network to drop a random set of neurons while
training the network. Ignoring several neurons for each iteration during the
training process is necessary, because if the network is fully connected,
neurons will become interdependent, leading to overfitting of the training data. For example, if the dropout function is set to 0.25, this means that 25\% of the existing
neurons within the network will be ignored during the training process.
\item[$\bullet$] The number of epochs can also influence the accuracy of a neural network. It
refers to the number of times all the training and validation datasets are
propagated through the GRU neural network. The standard procedure is to
increase the number of epochs until the chosen metric – in this case the MSE
– decreases for the validation set, while it continues to increase for the training
set, i.e. when the training set shows signs of overfitting.
\item[$\bullet$] The Mean Square Error (MSE): This is the average squared difference between the estimated values and the actual value.

\begin{center}
	$L_{MSE} = 1/N\sum_{k=1}^{N} ({\hat{y}}_{k}-y_k)^2$
\end{center}
It is also chosen as the loss function (between the predicted outputs and the actual outputs) and the performance measure(to assess the model fit while
training and validating the network) of the
LSTM neural network
\end{itemize}

The number of neurons, dropout function, activation functions and epochs are changed in each LSTM models to choose the one that performs best. That is, the LSTM with the lowest MSE value. This will be discussed in details in the next chapter.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Numerical comparisons}
For the empirical study, the day-ahead forecasting of the 1\% and 5\% VAR for daily log-returns(natural log of the new value divided by the initial value) of the following stock markets: NIKKEI 225, FTSE 100 and S\&P 500 is considered. The data is downloaded from DataStream. Each series (NIKKEI 225, FTSE 100 and S\&P 500) consist of 8477 daily price indices (measure of how prices change over a period of time), the start date and end date are 04/01/1988 and 30/06/2020 respectively. Upon calculating the log-return, which is given as 

\begin{center}
	$R_{log} = ln(\frac{R_f}{R_i})$
\end{center}
the data in the first row of the series vanishes leaving us with 8476 daily log-returns and 05/01/1988 as starting date. Basically, this means we use 8476 daily log-returns for our VaR estimations. This longer sample is desirable for our models, most especially the historical simulation and neural network as they work best with large data. Moreover, data contains periods of low and high volatilities, which mitigates the probability of the historical simulation being bias (underestimation or overestimation) in the return estimation.\newline

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/logNikkei}
	\caption{The series of log-returns of Nikkei 225}
	\label{logNikkei}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/logFTSE}
	\caption{The series of log-returns of FTSE 100}
	\label{logFTSE}
\end{figure}


\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/logS&P500}
	\caption{The series of log-returns of S\&P 500}
	\label{logSandP 500}
\end{figure}

\section{Partitioning the Dataset}
\subsection{LSTM Neural Network Model}

Generally, data is divided into two main parts in neural network models: training set and test set. However, an additional intermediate set called validation set (sometimes modelled as part of training), is sometimes employed in order to avoid overfitting. The training and validation data can be jointly referred to as In-sample data, while the test data is sometimes referred to as Out-of-sample data. In most literatures, the common choice for training set between 70\% to 90\% of the original dataset, and 10\% to 20\% of the training are used as validation dataset. The rest are, of course the testing dataset. \newline\newline

In this study, the first 7000 daily log-returns of each series (each series contains 8473 daily log-returns) are used as training dataset, which is around 83\% of each of the series. The last 700 (10\%) values (daily log-returns) of the training dataset are used for validation. The remaining 1476 daily log-returns are used for testing. However, the first 90 values in our test dataset vanishes due to use of lookahead (timesteps) of 90 days. Apparently, our resultant forecasts (out-of-sample) are 1386 daily log-returns. The dates for the data split are reported in the table below.
%\makeatletter
%\setlength\@fptop{0\p@}
%\makeatother
\newline\newline
\begin{table}[!h]
	\centering
	\begin{tabular}{l|cl}
		\hline \hline
		In-sample
		& out-of-sample\\ \hline
		Training set: 05/01/1988 – 27/02/2012
		& Test set
		: 10/03/2015 – 30/06/2020
	 \\
		Validation set: 28/02/2012– 03/11/2014
		\\
		\hline \hline
	\end{tabular}
	\caption{Data splits}
	%\vspace{128in}
	\label{firsttab}
\end{table}

An important pre-processing step is input normalization, as it is considered good practice for neural network training, data scaling helps neural networks train and converge faster. We use the z-score (StandardScaler): 

\begin{center}
	$X_{new} = \frac{X_{i}-\mu}{\sigma}$
\end{center}

where $X_{new}$ is the standardized data point, $X_{i}$ is the initial data point, $\mu$ is the sample mean and $\sigma$ is the sample variance.


\subsection{Historical simulation and GARCH(1,1) Volatility model}
For congruency with the LSTM model (in regards to number of predictions), we use a rolling window of 7090 for Historical simulation and GARCH(1,1) Volatility model, which stands as our in-sample data and we have 1386 out-of-sample data (predictions).

\subsection{Trial Results of the LSTM Neural Network}

As discussed in the previous chapter, the performance of our LSTM model is based on MSE. In this paper, we follow a best-out-of-5 approach, that means for each stock market, we train our model five times with different values of the hyperparameters and the best one (in each of the model training for the three stock market) is selected for VAR estimation. Tanh is the activation function in all models.\newline
\textbf{NIKKEI}\newline
The training and validation loss continues to decrease as the number of epochs increases until 200 epochs,
after which the model starts to overfit. This was made evident as a result of a slow and steady rise in the
validation loss after 200 epochs, while the training loss keeps reducing.
It was also observed that the most effective size of the LSTM network is 350, and the higher the intensity
of regularization applied, the better the model was able to perform.\newline

\begin{center}
	\begin{tabular}{||c c c c c||} 
		\hline
		Trials & Epochs & Dropout & Hidden Neurons & Validation result\\ [0.5ex] 
		\hline\hline
		1 & 500 & 0.5 & 256 & 0.00036662753 \\ 
		\hline
		2 & 300 & 0.75 & 256 & 0.0001696553 \\
		\hline
		3 & 300 & 0.75 & 350 & 0.00017357965 \\
		\hline
		4 & 200 & 0.5 & 256 & 0.0002184841 \\
		\hline
		5 & 200 & 0.75 & 350 & 0.00016831204\\ [1ex] 
		\hline
	\end{tabular}
\end{center}

In the first trial, the model is trained for 500 epochs, which is more than the desired 200 epochs. The intensity of
regularization is also low at 0.5, the LSTM network size is also low. As a result of the high number of
epochs and low regularization effect, it suffers from the highest variance and produced the worst result.\newline
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/Nik1}
	\caption{Training and Validation loss functions under Trial 1 (Nikkei 225))}
	\label{Nik1}
\end{figure}


 The second gives the second best result,as it is trained for more than 200 epochs, and
also the LSTM network at 256 fell short of 350. As a result of this, the model suffers from a higher bias as
compared to the last trial, because the model is not able to learn well as a result of the inadequate LSTM network.\newline\newline\newline\newline\newline\newline\newline\newline\newline\newline\newline
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/Nik2}
	\caption{Training and Validation loss functions under Trial 2 (Nikkei 225))}
	\label{Nik2}
\end{figure}

Trial 3 is the third in line, the model is trained for 300 epochs which is longer than the required 200 epochs,
this made the model to suffer from high variance. Since the LSTM is large although the right size, an increase
above the required number of epochs will lead the model to start to overfit rapidly, that was why this trial
performed worse than the second trial.\newline\newline
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/Nik3}
	\caption{Training and Validation loss functions under Trial 3 (Nikkei 225))}
	\label{Nik3}
\end{figure}


Trained with the desired 200 epochs, with a low dropout of 0.5, and a low LSTM size of 256. The forth trial
has the lower regularization effect of using a dropout of 0.5 and an insuffcient LSTM
network made the model suffer from higher bias.\newline\newline\newline
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/Nik4}
	\caption{Training and Validation loss functions under Trial 4 (Nikkei 225))}
	\label{Nik4}
\end{figure}

The best performed trial is the fifth trial. As a result of the 200 epochs the model trained for being within the range
of avoiding high variance (overfitting) and high bias (underfitting). The dropout regularization intensity is also high enough at 0.75,
and the size of the Long Short Term Memory (LSTM) network at 350 is large enough.\newline
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/Nik5}
	\caption{Training and Validation loss functions under Trial 5 (Nikkei 225))}
	\label{Nik5}
\end{figure}
\newline\textbf{FTSE 100}\newline

A decrease in the training and validation loss continues to occur as the number of epochs increases until 205
epochs, after which the model starts to overfit. This is made evident as a result of a slow and steady rise
in the validation loss after 205 epochs, while the training loss keeps reducing.
It was also observed that the most effective size of the LSTM network is 350, and the higher the intensity
of regularization applied, the better the model was able to perform.
\begin{center}
	\begin{tabular}{||c c c c c||} 
		\hline
		Trials & Epochs & Dropout & Hidden Neurons & Validation result\\ [0.5ex] 
		\hline\hline
		1 & 500 & 0.5 & 250 & 0.00013862312 \\ 
		\hline
		2 & 300 & 0.75 & 250 & 0.00012870964 \\
		\hline
		3 & 300 & 0.75 & 350 & 0.000117358715 \\
		\hline
		4 & 200 & 0.5 & 250 & 0.00012332022 \\
		\hline
		5 & 200 & 0.75 & 350 & 0.00011699893\\ [1ex] 
		\hline
	\end{tabular}
\end{center}

The last trial produced the best result, as a result of the 200 epochs used in the training, being within the range
of avoiding high variance and high bias. The dropout regularization intensity is also high enough at 0.75,
and the size of the Long Short Term Memory (LSTM) network at 350 is large enough.
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/FTSE5}
	\caption{Training and Validation loss functions under Trial 5 (FTSE 100))}
	\label{FTSE5}
\end{figure}
\newline The third attempt has the second lowest MSE, it fell short because it is trained with more than 200 epochs. As a
result of this, the model suffers from a higher variance as compared to trial 5.\newline\newline\newline\newline\newline\newline\newline\newline\newline\newline\newline\newline
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/FTSE3}
	\caption{Training and Validation loss functions under Trial 3 (FTSE 100))}
	\label{FTSE3}
\end{figure}
\newline Although, the forth trial is trained with the required 200 epochs but fall short, as a result of the low dropout of 0.5 and inadequate
LSTM network size. The low regularization intensity had the greatest effect, leading to high variance.\newline
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/FTSE4}
	\caption{Training and Validation loss functions under Trial 4 (FTSE 100))}
	\label{FTSE4}
\end{figure}
\newline The second trial is overtrained for 300 epochs, the dropout at 0.5 is low, and the LSTM network at 250, are what
led to a less impressive result compared to trial 5,3, and 4 \newline\newline\newline

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/FTSE2}
	\caption{Training and Validation loss functions under Trial 2 (FTSE 100))}
	\label{FTSE2}
\end{figure}

 Suffers the same set back as the second trial, the first trial is trained with an even larger number of epochs at 500. This made it
perform the worst in comparison with the rest of the trails.\newline\newline\newline
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/FTSE1}
	\caption{Training and Validation loss functions under Trial 1 (FTSE 100))}
	\label{FTSE1}
\end{figure}
 
 
 \textbf{S\&P500}\newline\newline
A decrease in the training and validation loss continues to occur as the number of epochs increases until 270
epochs, after which the model starts to overfit. This was made evident as a result of a slow and steady rise
in the validation loss after 270 epochs, while the training loss keeps reducing.

\begin{center}
	\begin{tabular}{||c c c c c||} 
		\hline
		Trials & Epochs & Dropout & Hidden Neurons & Validation result\\ [0.5ex] 
		\hline\hline
		1 & 500 & 0.5 & 250 & 0.00020557812 \\ 
		\hline
		2 & 300 & 0.75 & 250 & 0.00017026176 \\
		\hline
		3 & 300 & 0.75 & 350 & 0.00013683487 \\
		\hline
		4 & 270 & 0.5 & 256 & 0.00015936441 \\
		\hline
		5 & 270 & 0.8 & 356 & 0.00013847416 \\ [1ex] 
		\hline
	\end{tabular}
\end{center}



With the largest number of epochs of 500. The first trial suffers from severe overfitting, and made it perform the worst compared to the rest of the trials.\newline
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/sanp1}
	\caption{Training and Validation loss functions under Trial 1 (S\&P 500)}
	\label{sanp1}
\end{figure}
\newline The second trial is modelled with 300 epochs, the dropout at 0.5 is low, and the LSTM network at 250 neurons, are what
led to a less impressive result compared to the subsequent trials. \newline\newline\newline\newline\newline\newline\newline\newline\newline\newline\newline
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/sanp2}
	\caption{Training and Validation loss functions under Trial 2 (S\&P 500)}
	\label{sanp2}
\end{figure}
\newline The third attempt has the same number of epochs as second trial, produced the least MSE value, but still suffers from much overfitting despite increasing the dropout and the number of neurons.\newline
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/sanp3}
	\caption{Training and Validation loss functions under Trial 3 (S\&P 500)}
	\label{sanp3}
\end{figure}

The penultimate trial is trained with the sufficient 270 epochs, but as a result of the low dropout of 0.5 and inadequate LSTM
network size. The low regularization intensity has the greatest effect, leading to high variance.\newline
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/sanp4}
	\caption{Training and Validation loss functions under Trial 4 (S\&P 500)}
	\label{sanp4}
\end{figure}
\newline The final trial is trained with 270 epochs and the increased number of hidden neurons and dropout made it outperform the fourth trial and this is considered the best model.
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/sanp5}
	\caption{Training and Validation loss functions under Trial 5 (S\&P 500)}
	\label{sanp5}
\end{figure}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{appendix}
		\chapter{}
	
	Graphs of log-return series of each stock market	
	

	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	\chapter{}

	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
In all the graphs below, number of epochs is represented by the
horizontal axis (X-axis), while the loss functions are represented by the vertical axis
(Y-axis).



	
	
	






	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\\
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\chapter{Another example}
	\label{app_ex2}
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\section{More stuff}
	
	Bla bla.
	
\end{appendix}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\bibliographystyle{plain}
\bibliographystyle{abbrvnat}
\bibliography{literature/library}

\listoffigures
\listoftables

%\printindex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
